{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1AkBieW2QsrvmKX55xVxhy7-4Fy7ZyWzv",
      "authorship_tag": "ABX9TyMdTIR+hFwIf4ldAF7iNwzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VIJAYRUR/DL/blob/main/Copy_of_PS2_VGG_dogs_and_cats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVh2-COttmv9"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow,keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "XGVVJBxxtqLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "id": "-7E5t_89uFyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras import backend as K\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "# from keras.applications.imagenet_utils import _obtain_input_shape # this will work for older versions of keras. 2.2.0 or before\n",
        "# from keras.engine.topology import get_source_inputs"
      ],
      "metadata": {
        "id": "RiPkrddJuH1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model building\n",
        "\n",
        "def VGGupdated(input_tensor=None,classes=2):\n",
        "\n",
        "    img_rows, img_cols = 300, 300   # by default size is 224,224\n",
        "    img_channels = 3\n",
        "\n",
        "    img_dim = (img_rows, img_cols, img_channels)\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=img_dim)\n",
        "    else:\n",
        "        img_input = Input(tensor=input_tensor, shape=img_dim)\n",
        "\n",
        "\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "\n",
        "    # Classification block\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "    x = Dense(classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    # Create model.\n",
        "\n",
        "\n",
        "    model = Model(inputs = img_input, outputs = x, name='VGGdemo')\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "N2X9HRSTuKKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGGupdated(classes = 2) # bedroom and diningroom"
      ],
      "metadata": {
        "id": "9BEmVlYjuRLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LDuzhajNuTMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "dataset_path = os.listdir('/content/drive/MyDrive/test')\n",
        "\n",
        "animal_types = os.listdir('/content/drive/MyDrive/test')\n",
        "print (animal_types)  #what kinds of animals are in this dataset\n",
        "\n",
        "print(\"Types of rooms found: \", len(dataset_path))"
      ],
      "metadata": {
        "id": "XrYvEqC8uUm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = []\n",
        "\n",
        "for item in animal_types:\n",
        "    # Get all the file names\n",
        "    all_animals = os.listdir('/content/drive/MyDrive/test' + '/' +item)\n",
        "    # Add them to the lst\n",
        "    for i in all_animals:\n",
        "        lst.append((item, str('/content/drive/MyDrive/test' + '/' +item) + '/' + i))\n",
        "print(lst)"
      ],
      "metadata": {
        "id": "wNDlWvweu8rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a dataframe\n",
        "animals_df = pd.DataFrame(data=lst, columns=['animal name', 'image'])\n",
        "print(animals_df.head())"
      ],
      "metadata": {
        "id": "6d1Aw54YuWWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check how many samples for each category are present\n",
        "print(\"Total number of rooms in the dataset: \", len(animals_df))\n",
        "\n",
        "animals_count = animals_df['animal name'].value_counts()\n",
        "\n",
        "print(\"animals in each category: \")\n",
        "print(animals_count)"
      ],
      "metadata": {
        "id": "z1mzYwhMwbmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "path = '/content/drive/MyDrive/test/'\n",
        "\n",
        "\n",
        "im_size = 300\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "#resizing and adding images to img list and labels to labels list\n",
        "for i in animal_types:\n",
        "    data_path = path + str(i)\n",
        "    filenames = [i for i in os.listdir(data_path) ]\n",
        "\n",
        "    for f in filenames:\n",
        "        img = cv2.imread(data_path + '/' + f)\n",
        "        img = cv2.resize(img, (im_size, im_size))\n",
        "        images.append(img)\n",
        "        labels.append(i)\n"
      ],
      "metadata": {
        "id": "xQk7MUW0wdb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array(images)\n",
        "\n",
        "images = images.astype('float32') / 255*1.0\n",
        "images.shape\n"
      ],
      "metadata": {
        "id": "Z6JQTNdNwe2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pre processing data\n",
        "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
        "y=animals_df['animal name'].values\n",
        "print(y[:5])\n",
        "\n",
        "y_labelencoder = LabelEncoder ()\n",
        "y = y_labelencoder.fit_transform (y)\n",
        "print (y)"
      ],
      "metadata": {
        "id": "APE67RQCwroh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding labels\n",
        "y=y.reshape(-1,1)\n",
        "onehotencoder = OneHotEncoder()  #Converted  scalar output into vector output where the correct class will be 1 and other will be 0\n",
        "Y= onehotencoder.fit_transform(y)\n",
        "Y.shape"
      ],
      "metadata": {
        "id": "NxwECUJCwtL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "images, Y = shuffle(images, Y, random_state=1)\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(images, Y, test_size=0.3, random_state=415)\n",
        "\n",
        "#inpect the shape of the training and testing.\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "metadata": {
        "id": "1LkwoVyZwuvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "train_y = csr_matrix(train_y) # convert to SparseTensor if not already done\n",
        "train_y = np.array(train_y.toarray()) # convert to dense numpy array\n"
      ],
      "metadata": {
        "id": "LQmYDgUMwx-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_x, train_y, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "OdxBUzTcwz2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "test_y = csr_matrix(test_y) # convert to SparseTensor if not already done\n",
        "test_y = np.array(test_y.toarray()) # convert to dense numpy array\n",
        "\n",
        "preds = model.evaluate(test_x, test_y)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"accuracy = \" + str(preds[1]))"
      ],
      "metadata": {
        "id": "EdeUvxLSw1R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import imread, imshow\n",
        "import tensorflow as tf\n",
        "img_path = '/content/drive/MyDrive/Classroom/dog.jpg'\n",
        "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(300, 300))\n",
        "\n",
        "x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
        "\n",
        "print('Input image shape:', x.shape)\n",
        "\n",
        "my_image = imread(img_path)\n",
        "imshow(my_image)\n"
      ],
      "metadata": {
        "id": "i5FjPoJQx6VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(x))"
      ],
      "metadata": {
        "id": "ErEG1XeCzE24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hence dog agaya but model accuracy is 50 percent , feed more data"
      ],
      "metadata": {
        "id": "SvuPdhli0K-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bkrDkf4d0R9w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}